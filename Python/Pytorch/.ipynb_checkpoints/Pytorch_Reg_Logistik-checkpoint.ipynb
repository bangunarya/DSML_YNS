{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import module torch dan torchvision yang memiliki dataset mnist\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d818b8fdb3a84ffc9d79513d276cc0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d3ed421b774a95a8d66188ac3caa63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192e4089868c4841b8d20d4e89bbae36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b564ba73e6492a8da71b712b1757e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pisahkan antara dataset untuk training dan dataset untuk test, perlu diingat disini pytorch menggunakan format\n",
    "# data tensor, sehingga ToTensor() disini berguna untuk mengubah format data menjadi tensor\n",
    "train_dataset = dsets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = dsets.MNIST(root='./data', train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisi variabel dalam optimisasi\n",
    "\n",
    "# Batch size merupakan banyaknya data yang di proses misal jika kita mempunyai data 10000\n",
    "# dengan batch size 200, berarti kita memiliki 50 batch dengan per batch kita mengeksekusi 200 data \n",
    "batch_size = 100\n",
    "\n",
    "# Banyaknya iterasi pada gradient\n",
    "n_iters = 6000\n",
    "\n",
    "# Epoch berarti berapa kali algoritma kita akan bekerja untuk memproses semua data/per batch\n",
    "epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "# Banyaknya input data kita, ingat kita memiliki gambar MNIST dengan dimensi 28 x 28 sehingga kita memiliki\n",
    "# Vektorisasi 784\n",
    "input_dim = 784\n",
    "# Banyaknya kelas, disini kita ingin mengklasifikasikan multikelas dari 0,1,..9\n",
    "output_dim = 10\n",
    "# Learning rate merupakan parameter skala dalam turunan, ingat parameter alpha\n",
    "lr_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variabel training data dan test data\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dalam pytorch kita harus mendefinisikan class, ingat dalam class di object oriented program\n",
    "# Kita memiliki beberapa atribut, atau metoda, dsini kita memiliki constructor __init__\n",
    "# yang menggunakan fungsi super agar kita mendapatkan properti dari paremt torch.nn.Module\n",
    "# Metoda forward merupakan forward model kita\n",
    "\n",
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.linear(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kita buat instance dari kelas LogisticRegresion dengan input dimensi sebanyak gambar kita dan output dimensi \n",
    "# Banyaknya kelas\n",
    "model = LogisticRegression(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disini kita menentukan cost function kita, yaitu seperti yang kita pelajari disebut juga cross entropy\n",
    "criterion = torch.nn.CrossEntropyLoss() # computes softmax and then the cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metode gradient method yang kita gunakan, di dalam modul yang kita pelajari kita hanya menggunakan simpel gradient\n",
    "# Namun pada kenyataannya sekarang ada banyak variasi metode gradient, disini kita menggunakan SGD (Stochastic Gradient Method)\n",
    "# Dengan learning rate yang kita tentukan\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 1.9379119873046875. Accuracy: 66.80999755859375.\n",
      "Iteration: 1000. Loss: 1.5509116649627686. Accuracy: 76.0999984741211.\n",
      "Iteration: 1500. Loss: 1.332176923751831. Accuracy: 78.8499984741211.\n",
      "Iteration: 2000. Loss: 1.204288363456726. Accuracy: 80.51000213623047.\n",
      "Iteration: 2500. Loss: 1.0564988851547241. Accuracy: 81.7300033569336.\n",
      "Iteration: 3000. Loss: 1.0266402959823608. Accuracy: 82.62000274658203.\n",
      "Iteration: 3500. Loss: 0.9627998471260071. Accuracy: 83.30999755859375.\n",
      "Iteration: 4000. Loss: 0.8270407915115356. Accuracy: 83.72000122070312.\n",
      "Iteration: 4500. Loss: 0.8181248307228088. Accuracy: 84.20999908447266.\n",
      "Iteration: 5000. Loss: 0.7286779880523682. Accuracy: 84.58999633789062.\n",
      "Iteration: 5500. Loss: 0.8189718127250671. Accuracy: 84.91999816894531.\n",
      "Iteration: 6000. Loss: 0.7198503613471985. Accuracy: 85.33000183105469.\n"
     ]
    }
   ],
   "source": [
    "# Masuk kedalam iterasi per epoch\n",
    "iter = 0\n",
    "for epoch in range(int(epochs)):\n",
    "    # Load semua data dan label nya\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.view(-1, 28 * 28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Definisikan dan inisialisasi gradient dengan 0\n",
    "        optimizer.zero_grad()\n",
    "        # Hitung instance kita dengan input data dan disini\n",
    "        # Kita hitung forward model\n",
    "        outputs = model(images)\n",
    "        # Bandingkan dengan label dengan menggunakan cost function kita\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Lakukan prosess backward dengan stepsize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Tambah iterasi\n",
    "        iter+=1\n",
    "        # Condisi agar kita menampilkan nilai tiap iterasi yang habis dibagi 500\n",
    "        if iter%500==0:\n",
    "            # Hitung akurasi network kita dan print hasilnya\n",
    "            # Dengan menggunakan test data\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in test_loader:\n",
    "                images = Variable(images.view(-1, 28*28))\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total+= labels.size(0)\n",
    "                # Untuk gpu, kembalikan predicted and labels ke cpu\n",
    "                correct+= (predicted == labels).sum()\n",
    "            accuracy = 100 * correct/total\n",
    "            print(\"Iteration: {}. Loss: {}. Accuracy: {}.\".format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
